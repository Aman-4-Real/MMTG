{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b545cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from paddlenlp.metrics import Distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39d19e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path1 = \"../src_v8_rebuttal/res/lr1e-5_bs96_kl02_add_tk1_tp0_tm1o1_rpt1o5_no_alpha.txt\"\n",
    "# path1 = \"../src_v8_rebuttal/res/test3000/lr1e-5_bs96_kl02_add_tk1_tp0_tm1o1_rpt1o5.txt\"\n",
    "path1 = \"../src_images2poem/res/test3000/lr1e-5_bs256_tk1_tp0_tm1o1_rpt1o5.txt\"\n",
    "# path2 = \"../src_v8_rebuttal/res/lr1e-5_bs96_kl02_add_tk1_tp0_tm1o1_rpt1o5_no_alpha_disorder.txt\"\n",
    "# path2 = \"../src_v8_rebuttal/res/test3000/lr1e-5_bs96_kl02_add_tk1_tp0_tm1o1_rpt1o5_disorder.txt\"\n",
    "path2 = \"../src_images2poem/res/test3000/lr1e-5_bs256_tk1_tp0_tm1o1_rpt1o5_disorder.txt\"\n",
    "with open(path1, \"r\") as f:\n",
    "    data1 = f.readlines()\n",
    "data1 = [item.strip() for item in data1]\n",
    "with open(path2, \"r\") as f:\n",
    "    data2 = f.readlines()\n",
    "data2 = [item.strip() for item in data2]\n",
    "\n",
    "with open(\"../src_v5_refine/res/lr1e-5_bs96_kl02_tk1_tp0_tm1o1_rpt1o5_wo_topic.txt\", \"r\") as f:\n",
    "    data3 = f.readlines()\n",
    "data3 = [item.strip() for item in data3]\n",
    "with open(\"../src_v5_refine/res/lr1e-5_bs96_kl02_tk1_tp0_tm1o1_rpt1o5_wo_topic_disorder.txt\", \"r\") as f:\n",
    "    data4 = f.readlines()\n",
    "data4 = [item.strip() for item in data4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36ff9908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,\n",
       " '我们的爱情，屋顶上有一个小孩，他说这是最后一次，在地铁里面，那些人都不知道，他说这是最后的天气，但它也许会变成，灯塔下面，还没到站，就已经被风吹散',\n",
       " 500,\n",
       " '我们的爱情，屋企会发售，一个人逛街，在这里看电影，你说要去哪裡，有些事不必太多，屋顶上灯光，照耀着夜晚，谁亦没法预料，天空中闪烁星')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data1), data1[0], len(data2), data2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc31d64",
   "metadata": {},
   "source": [
    "## 计算delta_distinct (disorder的distinct求平均 - order的distinct) => 不理想"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "722351f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_delta_dist(data1, data2, n):\n",
    "    res = []\n",
    "    for i in range(len(data1)):\n",
    "        ref = data1[i]\n",
    "        lines = data2[i*10:(i+1)*10]\n",
    "        distinct1 = Distinct(n_size=n)\n",
    "        distinct1.add_inst(list(ref))\n",
    "        tmp = []\n",
    "        for line in lines:\n",
    "            distinct2 = Distinct(n_size=n)\n",
    "            distinct2.add_inst(list(line))\n",
    "            tmp.append(distinct2.score())\n",
    "        res.append(np.mean(tmp) - distinct1.score())\n",
    "    print(np.mean(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05317d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016364210533163743\n",
      "0.00034822074323330064\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "cal_delta_dist(data1, data2, n)\n",
    "cal_delta_dist(data3, data4, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c8ad15",
   "metadata": {},
   "source": [
    "## 计算cal_new_ngrams_rate => 还可以"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9da28a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngram_set(input_list, ngram_num):\n",
    "    if len(input_list) < ngram_num:\n",
    "        return set()\n",
    "    if len(input_list) <= ngram_num:\n",
    "        return {tuple(list(input_list))}\n",
    "    else:\n",
    "        return set(zip(*[input_list[i:] for i in range(ngram_num)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bdef533",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('文', '本'), ('本', '，'), ('测', '试'), ('试', '文'), ('这', '是'), ('，', '测'), ('的', '文'), ('是', '测'), ('试', '的')} {('另', '一'), ('一', '个'), ('文', '本'), ('个', '文')} {('本', '，'), ('测', '试'), ('试', '文'), ('这', '是'), ('，', '测'), ('的', '文'), ('是', '测'), ('试', '的')}\n"
     ]
    }
   ],
   "source": [
    "a = create_ngram_set(\"这是测试文本，测试的文本\",2)\n",
    "b = create_ngram_set(\"另一个文本\", 2)\n",
    "print(a, b, a - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d178e78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_new_ngrams_rate(ref_data, thep_data, n):\n",
    "    res = []\n",
    "    for i in range(len(ref_data)):\n",
    "        ref = ref_data[i]\n",
    "#         lines = [thep_data[i]]\n",
    "        lines = thep_data[i*3:(i+1)*3] # 10\n",
    "        ref_unique_ngrams = create_ngram_set(ref, n)\n",
    "        tmp = []\n",
    "        for line in lines:\n",
    "            tmp_unique_ngrams = create_ngram_set(line, n)\n",
    "            tmp.append(len(tmp_unique_ngrams-ref_unique_ngrams)/len(ref_unique_ngrams|tmp_unique_ngrams))\n",
    "        res.append(np.mean(tmp))\n",
    "    print(np.mean(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81f827c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02821468760758687\n",
      "0.047229054714128936\n"
     ]
    }
   ],
   "source": [
    "# n = 2\n",
    "cal_new_ngrams_rate(data1, data2, 1)\n",
    "cal_new_ngrams_rate(data1, data2, 2)\n",
    "# cal_new_ngrams_rate(data3, data4, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f380e0",
   "metadata": {},
   "source": [
    "## 计算uni(AUB)/AUB => 不理想"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adc0ce7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngram_set(input_list, ngram_num):\n",
    "    if len(input_list) < ngram_num:\n",
    "        return set()\n",
    "    if len(input_list) <= ngram_num:\n",
    "        return {tuple(list(input_list))}\n",
    "    else:\n",
    "        return list(zip(*[input_list[i:] for i in range(ngram_num)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7304fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('这', '是'), ('是', '测'), ('测', '试'), ('试', '文'), ('文', '本')] [('另', '一'), ('一', '个'), ('个', '文'), ('文', '本')]\n"
     ]
    }
   ],
   "source": [
    "a = create_ngram_set(\"这是测试文本\",2)\n",
    "b = create_ngram_set(\"另一个文本\", 2)\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61b3ffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_uni_ngrams_rate(ref_data, thep_data, n):\n",
    "    res = []\n",
    "    for i in range(len(ref_data)):\n",
    "        ref = ref_data[i]\n",
    "        lines = thep_data[i*10:(i+1)*10]\n",
    "        ref_sents = ref.split('，')\n",
    "        ref_unique_ngrams = []\n",
    "        for sent in ref_sents:\n",
    "            ref_unique_ngrams += create_ngram_set(sent, n)\n",
    "        tmp = []\n",
    "        for line in lines:\n",
    "            line_sents = line.split('，')\n",
    "            tmp_unique_ngrams = []\n",
    "            for sent in line_sents:\n",
    "                tmp_unique_ngrams += create_ngram_set(sent, n)\n",
    "#             tmp.append(len(set(tmp_unique_ngrams)-set(ref_unique_ngrams))/len(set(ref_unique_ngrams)|set(tmp_unique_ngrams)))\n",
    "            tmp.append(len(set(tmp_unique_ngrams+ref_unique_ngrams))/(len(ref_unique_ngrams)+len(tmp_unique_ngrams)))\n",
    "#             tmp.append(len(set(tmp_unique_ngrams)-set(ref_unique_ngrams))/(len(set(ref_unique_ngrams))+len(set(tmp_unique_ngrams))))\n",
    "        res.append(np.mean(tmp))\n",
    "    print(np.mean(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2725c836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8578730258117452\n",
      "0.8338766599619114\n"
     ]
    }
   ],
   "source": [
    "n = 2\n",
    "cal_uni_ngrams_rate(data1, data2, n)\n",
    "cal_uni_ngrams_rate(data3, data4, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7744a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e657590b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
